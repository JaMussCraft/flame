{
  "taskid": "llama32_1b_trainer_001",
  "backend": "p2p",
  "brokers": [
    {
      "host": "localhost",
      "sort": "mqtt"
    },
    {
      "host": "localhost:10104",
      "sort": "p2p"
    }
  ],
  "groupAssociation": {
    "param-channel": "default"
  },
  "channels": [
    {
      "description": "Model update is sent from trainer to aggregator and vice-versa",
      "groupBy": {
        "type": "tag",
        "value": [
          "default"
        ]
      },
      "name": "param-channel",
      "pair": [
        "trainer",
        "aggregator"
      ],
      "funcTags": {
        "aggregator": [
          "distribute",
          "aggregate"
        ],
        "trainer": [
          "fetch",
          "upload"
        ]
      }
    }
  ],
  "dataset": "custom_text",
  "dependencies": [
    "numpy >= 1.2.0",
    "torch >= 1.12.0",
    "tiktoken"
  ],
  "hyperparameters": {
    "batch_size": 4,
    "learning_rate": 1e-5,
    "rank": 0,
    "world_size": 2,
    "epochs": 1,
    "seed": 42,
    "max_seq_len": 512,
    "max_batch_size": 8,
    "ckpt_dir": "../checkpoints",
    "weight_decay": 0.01,
    "data_path": "train_data.txt"
  },
  "baseModel": {
    "name": "llama-3.2-1b",
    "version": 1
  },
  "job": {
    "id": "622a358619ab59012eabeefb",
    "name": "llama32_1b_federated"
  },
  "registry": {
    "sort": "dummy",
    "uri": ""
  },
  "selector": {
    "sort": "default",
    "kwargs": {}
  },
  "optimizer": {
    "sort": "fedavg",
    "kwargs": {}
  },
  "maxRunTime": 3600,
  "realm": "default/us/west",
  "role": "trainer"
}
